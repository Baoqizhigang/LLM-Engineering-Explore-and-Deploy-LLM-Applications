{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc88a354-77a7-4e99-bed3-a03e570175dd",
   "metadata": {},
   "source": [
    "# Instant Gratification!\n",
    "Let's build a useful LLM solution - in a matter of minutes.\n",
    "\n",
    "Our goal is to code a new kind of Web Browser. Give it a URL, and it will respond with a summary. The Reader's Digest of the internet!!\n",
    "\n",
    "Before starting, be sure to create your API key with OpenAI and add it to the .env file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7906c141-a36f-438a-a733-fe12887adbb7",
   "metadata": {},
   "source": [
    "# Overall Flow of the Code\n",
    "\n",
    "Load Environment Variables: The .env file is loaded, which likely contains the OpenAI API key.\n",
    "\n",
    "Fetch Webpage Content: The requests library is used to make an HTTP request to the target webpage and retrieve its HTML content.\n",
    "\n",
    "Parse HTML with BeautifulSoup: Once the HTML is fetched, BeautifulSoup is employed to extract the relevant textual content (e.g., removing headers, footers, and other irrelevant HTML tags).\n",
    "\n",
    "Call GPT-4: After obtaining the clean webpage content, the OpenAI library is used to send the text to GPT-4 and request a summary.\n",
    "\n",
    "Display the Summary: The summary generated by GPT-4 is displayed in markdown format within the notebook using IPython.display."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b756991-199f-4267-9a64-627d86081965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The os module is a standard Python library that provides utilities for interacting with the operating system, \n",
    "# including environment variable management and file system access.\n",
    "# In this specific code, it is used to fetch environment variables (such as API keys) from the system or to access file paths.\n",
    "import os\n",
    "\n",
    "# The requests library is used to make HTTP requests to retrieve the contents of a web page. \n",
    "# In this project, it will be used to fetch the HTML of the page that needs to be summarized.\n",
    "# This library simplifies making HTTP requests, such as GET and POST, handling network errors, \n",
    "# and providing access to response content in different formats (text, JSON, etc.).\n",
    "# This step is essential to retrieve and prepare text data before summarization using GPT-4.\n",
    "import requests\n",
    "\n",
    "# The load_dotenv function is used to load environment variables from a .env file into the Python environment. \n",
    "# .env files contain environment-specific variables and are loaded by dotenv to prevent hard-coding sensitive information in the script.\n",
    "# The OpenAI API key, which will be required to interact with GPT-4, is stored in this .env file.\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# BeautifulSoup is part of the bs4 library and is used to parse and extract data from HTML and XML documents. \n",
    "# After fetching the web page content using requests, BeautifulSoup helps extract clean, readable text from the raw HTML, \n",
    "# which can then be summarized by the GPT-4 model.\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# These functions are used to display rich output (like markdown-formatted text) in Jupyter notebooks. \n",
    "# display allows you to render different types of objects in an IPython (Jupyter) environment. \n",
    "# Markdown renders text formatted using markdown syntax (like headings, bold, italics, etc.)\n",
    "# Once the webpage is summarized, the output can be shown in a readable, structured markdown format.\n",
    "from IPython.display import Markdown, display\n",
    "\n",
    "# This imports the OpenAI library, which allows interaction with OpenAI’s models (including GPT-4). \n",
    "# The script will use this library to send text data to the GPT-4 model and retrieve the summarized version.\n",
    "# The OpenAI Python package provides an interface for making requests to OpenAI’s API. \n",
    "# This is where API keys and requests are configured to interact with GPT-4, specifying parameters like the model to use, prompt, and temperature.\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37f3ebf-ca5c-4e37-9d01-5d1feb209699",
   "metadata": {},
   "source": [
    "# Key Concepts and Mechanism Behind the Class:\n",
    "# Web Scraping:\n",
    "This class effectively scrapes a webpage by making an HTTP request to the URL and parsing the HTML to extract meaningful data.\n",
    "Tools like requests and BeautifulSoup are commonly used for web scraping because they simplify the process of fetching and parsing HTML.\n",
    "\n",
    "# Data Cleaning:\n",
    "Before sending text to an LLM like GPT-4, it’s important to clean it. This code removes noisy elements (like scripts, styles, etc.) that would confuse or overwhelm the summarization model.\n",
    "The decompose() method ensures that these elements are completely removed from the parsed HTML.\n",
    "\n",
    "# LLM Input Preparation:\n",
    "Large language models like GPT-4 work best when provided with clean, structured input. This class cleans and prepares the text, ensuring that only relevant content is sent to the model.\n",
    "The clean, structured content improves the model’s ability to generate accurate and concise summaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "00aecbe1-3618-448a-b223-f93acbd2919a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This class is designed to encapsulate the essential elements of a webpage (URL, title, and main text content). \n",
    "# Once instantiated with a URL, it automatically fetches and processes the webpage to extract these details.\n",
    "# Object-oriented design is used here to wrap the webpage-related functionality into a single object, making it easier to manage and use. \n",
    "class Website:\n",
    "    url: str # This is a string attribute where the user or developer provides the URL of the webpage that will be fetched and summarized.\n",
    "    title: str# The title of a webpage is found in the <title> tag of the HTML document. If no title is found, a fallback value \"No title found\" is set.\n",
    "    text: str # The text content is extracted from the HTML <body> tag, after cleaning out irrelevant elements (like scripts and images).\n",
    "    \n",
    "    def __init__(self, url): # The constructor is responsible for initializing the Website object with the URL\n",
    "        self.url = url # The provided URL is stored in the url attribute of the instance.\n",
    "        \n",
    "        response = requests.get(url) # This line makes an HTTP GET request to fetch the HTML content of the webpage using the requests library.\n",
    "        \n",
    "        soup = BeautifulSoup(response.content, 'html.parser') # The fetched HTML content is passed to BeautifulSoup for parsing\n",
    "        \n",
    "        #  The title of the webpage is extracted from the <title> tag. If no <title> tag exists, a fallback string \"No title found\" is used.       \n",
    "        self.title = soup.title.string if soup.title else \"No title found\"\n",
    "        \n",
    "        # This loop removes certain irrelevant tags from the HTML, such as scripts, styles, images, and input fields. \n",
    "        # These tags don’t contain useful textual content for summarization and should be excluded.\n",
    "        # The soup.body([\"script\", \"style\", \"img\", \"input\"]) method finds all elements in the body that match the tags script, style, img, and input.\n",
    "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
    "            #  Completely removes these elements from the DOM tree. This ensures they don’t interfere with the extracted text.\n",
    "            irrelevant.decompose()\n",
    "\n",
    "        # After cleaning the HTML, this line extracts the remaining text from the webpage’s <body> tag.\n",
    "        # get_text(separator=\"\\n\", strip=True) is a BeautifulSoup method that retrieves all the text content from an HTML element (in this case, the body).\n",
    "        # separator=\"\\n\" ensures that different sections of text are separated by a newline when extracted. This helps in preserving the structure of the text.\n",
    "        # strip=True: removes leading and trailing whitespace from the text.\n",
    "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1e0311-5d42-4d44-9097-493ccc6df3d2",
   "metadata": {},
   "source": [
    "# Connecting to OpenAI\n",
    "The next cell is where we load in the environment variables in your .env file and connect to OpenAI.\n",
    "\n",
    "Troubleshooting if you have problems:\n",
    "\n",
    "OpenAI takes a few minutes to register after you set up an account. If you receive an error about being over quota, try waiting a few minutes and try again.\n",
    "As a fallback, replace the line openai = OpenAI() with openai = OpenAI(api_key=\"your-key-here\") - while it's not recommended to hard code tokens in Jupyter lab, because then you can't share your lab with others, it's a workaround for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f71e5db-b8bd-4885-ba82-90ebca198baa",
   "metadata": {},
   "source": [
    "Setting the API key in the environment and initializing the OpenAI client to interact with OpenAI’s GPT-4 API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd077884-5585-4323-b679-1e26f2a71ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the environment variables defined in the .env file into the current Python environment.\n",
    "load_dotenv()\n",
    "\n",
    "# This line ensures that the OpenAI API key is stored in the os.environ dictionary. \n",
    "# This dictionary holds all environment variables, which can be accessed by the script at runtime.\n",
    "# If the key is not found in the environment, it defaults to 'your-key-if-not-using-env'.\n",
    "# os.environ['OPENAI_API_KEY']: This explicitly sets the environment variable OPENAI_API_KEY to be used by the OpenAI client.\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "\n",
    "# This initializes an instance of the OpenAI class, which will be used to interact with the OpenAI API (in this case, GPT-4).\n",
    "# The OpenAI() class is part of the OpenAI Python package, which provides an interface for communicating with OpenAI’s API. \n",
    "# Once initialized, it enables you to call different models (like GPT-4) and send prompts for completion, summarization, and other NLP tasks.\n",
    "openai = OpenAI()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2281bcff-791f-4448-8491-a0d570ba529f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Home - Edward Donner\n",
      "Home\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Well, hi there.\n",
      "I’m Ed. I like writing code and experimenting with LLMs, and hopefully you’re here because you do too. I also enjoy DJing (but I’m badly out of practice), amateur electronic music production (\n",
      "very\n",
      "amateur) and losing myself in\n",
      "Hacker News\n",
      ", nodding my head sagely to things I only half understand.\n",
      "I’m the co-founder and CTO of\n",
      "Nebula.io\n",
      ". We’re applying AI to a field where it can make a massive, positive impact: helping people discover their potential and pursue their reason for being. Recruiters use our product today to source, understand, engage and manage talent. I’m previously the founder and CEO of AI startup untapt,\n",
      "acquired in 2021\n",
      ".\n",
      "We work with groundbreaking, proprietary LLMs verticalized for talent, we’ve\n",
      "patented\n",
      "our matching model, and our award-winning platform has happy customers and tons of press coverage.\n",
      "Connect\n",
      "with me for more!\n",
      "August 6, 2024\n",
      "Outsmart LLM Arena – a battle of diplomacy and deviousness\n",
      "June 26, 2024\n",
      "Choosing the Right LLM: Toolkit and Resources\n",
      "February 7, 2024\n",
      "Fine-tuning an LLM on your texts: a simulation of you\n",
      "January 31, 2024\n",
      "Fine-tuning an LLM on your texts: part 4 – QLoRA\n",
      "Navigation\n",
      "Home\n",
      "Outsmart\n",
      "An arena that pits LLMs against each other in a battle of diplomacy and deviousness\n",
      "About\n",
      "Posts\n",
      "Get in touch\n",
      "ed [at] edwarddonner [dot] com\n",
      "www.edwarddonner.com\n",
      "Follow me\n",
      "LinkedIn\n",
      "Twitter\n",
      "Facebook\n",
      "Subscribe to newsletter\n",
      "Type your email…\n",
      "Subscribe\n"
     ]
    }
   ],
   "source": [
    "# Let's try one out\n",
    "\n",
    "# Instantiate a Website Object: \n",
    "ed = Website(\"https://edwarddonner.com\") # provide a URL to the class constructor, which fetches and processes the webpage.\n",
    "\n",
    "# Access Webpage Data: After initialization, you can access the url, title, and text attributes of the object.\n",
    "print(ed.title) # Displays the webpage's title\n",
    "print(ed.text) # Displays the cleaned webpage text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715af809-b995-4c0f-96f4-6078fd801758",
   "metadata": {},
   "source": [
    "# system_prompt\n",
    "This string defines the system-level instructions given to GPT-4. \n",
    "It sets the behavior and tone of the model by specifying that it should act as an assistant that provides a summary of a website while ignoring irrelevant content (like navigation links)\n",
    "# System Role: \n",
    "GPT-4 can be guided to behave in specific ways based on the system prompt. Here, it's being instructed to provide a summary and to ignore text related to navigation, which is often not useful in a website summary.\n",
    "# Markdown: \n",
    "The instruction to \"Respond in markdown\" ensures that the response is formatted in a way suitable for rendering within markdown viewers (like in Jupyter notebooks or Markdown editors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7788b138-fab4-4c08-8e56-390aea96d0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"You are an assistant that analyzes the contents of a website \\\n",
    "and provides a short summary, ignoring text that might be navigation related. \\\n",
    "Respond in markdown.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaccc559-72df-4faa-b92a-5481a18b0b12",
   "metadata": {},
   "source": [
    "# user_prompt_for(website)\n",
    "This function generates the user-specific prompt to send to the GPT-4 model. It describes the website's title and content, then asks the model to summarize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "308d892b-16fa-4224-b3de-100d60bb502a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_prompt_for(website):\n",
    "    # The title of the webpage (website.title) is dynamically inserted into the user prompt, which gives GPT-4 context about the content it's summarizing.\n",
    "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
    "    user_prompt += \"The contents of this website is as follows; \\\n",
    "please provide a short summary of this website in markdown. \\\n",
    "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
    "    # The text content extracted from the webpage (website.text) is appended after the main prompt, asking GPT-4 to summarize it.\n",
    "    user_prompt += website.text\n",
    "    return user_prompt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38bc5850-1cdb-4203-9023-3a911c6fa853",
   "metadata": {},
   "source": [
    "# messages_for(website)\n",
    "This function generates the entire message structure needed for a conversation with GPT-4. It includes both the system prompt and the user prompt (which was created in the user_prompt_for function). This structure is required when working with OpenAI’s chat-based models, such as GPT-4. TThe function returns a list of message objects that represent the conversation:\n",
    "\n",
    "System Message: Defines the assistant's role and behavior.\n",
    "\n",
    "User Message: Contains the dynamically generated user prompt, which gives context and instructions to GPT-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed7b7fc-dc91-4319-aa49-19cf888d04b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def messages_for(website):\n",
    "    return [\n",
    "        {\"role\": \"system\", \"content\": system_prompt}, # The system message sets the model's role\n",
    "        {\"role\": \"user\", \"content\": user_prompt_for(website)} # The user message describes the task at hand.\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371fe6fc-e90d-470b-8dc7-e556128d1cfe",
   "metadata": {},
   "source": [
    "# summarize(url)\n",
    "This is the main function that orchestrates the webpage summarization process. It takes in a URL, fetches the webpage content, and then sends a prompt to GPT-4 to generate a summary.\n",
    "\n",
    "Website Object: \n",
    "The function first creates a Website object for the given URL. This object (from the earlier code) extracts the webpage's title and main text content.\n",
    "\n",
    "API Call to GPT-4: \n",
    "After generating the necessary messages (using messages_for), it makes a call to OpenAI's GPT-4 API using the openai.chat.completions.create() method. This sends the messages to the model and retrieves the generated summary.\n",
    "\n",
    "Return Summary: \n",
    "The function returns the summary produced by GPT-4 from response.choices[0].message.content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "778d4c9f-6b9e-4e9c-9714-75acb22e6d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize(url):\n",
    "    website = Website(url)  # Initialize the Website object for the given URL\n",
    "    \n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",  # GPT-4 model variant\n",
    "        messages=messages_for(website)  # Provide the system and user messages\n",
    "    )\n",
    "    return response.choices[0].message.content  # Return the generated summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6374f7c4-6aa8-4120-8cfd-aa1c7603f424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Website Summary - Edward Donner\\n\\nEdward Donner\\'s website features a personal introduction and showcases his interests in coding, LLMs (Large Language Models), DJing, and electronic music production. He is the co-founder and CTO of Nebula.io, which utilizes AI to improve talent discovery and recruitment. Previously, he founded the AI startup untapt, acquired in 2021.\\n\\n## Recent Posts\\n- **August 6, 2024**: Introduced \"Outsmart LLM Arena,\" a platform for LLMs to engage in diplomacy and competitive scenarios.\\n- **June 26, 2024**: Provided guidance on selecting the right LLM, including tools and resources.\\n- **February 7, 2024**: Discussed methods for fine-tuning LLMs based on individual texts in a simulated manner.\\n- **January 31, 2024**: Continued the discussion on fine-tuning LLMs, specifically focusing on QLoRA techniques.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarize(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17fa86a7-23e2-4319-84fa-2d5b528eb23c",
   "metadata": {},
   "source": [
    "# display_summary(url)\n",
    "This function ties everything together. It first generates a summary of the webpage provided by the url, then displays that summary in markdown format using IPython.display.\n",
    "\n",
    "Call to summarize(url):\n",
    "The function first calls summarize(url) to generate a summary of the given webpage. This function was defined earlier and is responsible for retrieving the webpage content, sending it to GPT-4, and getting the summarized text.\n",
    "\n",
    "display(Markdown(summary)): The display() function from the IPython package is used to render the summary in a notebook.\n",
    "\n",
    "Markdown(summary) is used to format the output as markdown. This ensures that any markdown syntax (like headers, lists, bold, or italic text) in the summary is rendered properly when displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cd053c2-11eb-4c29-8f72-5ab4c6511d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_summary(url):\n",
    "    summary = summarize(url)  # Generate summary using the summarize function\n",
    "    display(Markdown(summary))  # Display the summary in markdown format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2ff1c6a0-971f-4888-8984-bfe1b717784d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of Edward Donner's Website\n",
       "\n",
       "Edward Donner's website serves as a platform for his interests in coding, experimenting with large language models (LLMs), and electronic music production. As the co-founder and CTO of Nebula.io, he focuses on applying AI to improve talent discovery and management. His previous venture, untapt, was acquired in 2021, complementing his extensive experience in the AI field.\n",
       "\n",
       "## Recent Posts\n",
       "- **August 6, 2024**: **Outsmart LLM Arena** – A competitive environment designed for LLMs, emphasizing strategies involving diplomacy and cunning.\n",
       "- **June 26, 2024**: **Choosing the Right LLM: Toolkit and Resources** – Guidance on selecting appropriate LLMs for various applications.\n",
       "- **February 7, 2024**: **Fine-tuning an LLM on your texts: a simulation of you** – Insights into customizing LLMs using personal text data.\n",
       "- **January 31, 2024**: **Fine-tuning an LLM on your texts: part 4 – QLoRA** – A continuation of the fine-tuning discussion, focusing on the QLoRA method."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This line calls the display_summary function with the URL https://edwarddonner.com, initiating the entire process of webpage summarization and display.\n",
    "# The URL https://edwarddonner.com is passed to summarize, which extracts the webpage content and generates a summary using GPT-4.\n",
    "# The summary is then displayed in markdown format within the notebook environment\n",
    "display_summary(\"https://edwarddonner.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3180cbb7-6f8d-4ef6-b6c9-113f3e5730a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Summary of CNN Website\n",
       "\n",
       "The CNN website provides comprehensive coverage of breaking news, latest updates, and in-depth articles across various categories including US news, world events, politics, business, health, entertainment, travel, sports, and science. The site features live broadcasts, audio and video content, and articles on trending topics and current events.\n",
       "\n",
       "## Latest News Highlights\n",
       "- **Hurricane Helene**: The hurricane has intensified to Category 4, with extreme winds and storm surge affecting the Florida coast.\n",
       "- **NTSB Warning**: An urgent safety warning has been issued concerning certain Boeing 737 models.\n",
       "- **New York City Mayor**: Eric Adams faces mounting pressure and legal scrutiny, including a five-count indictment.\n",
       "- **Ukraine-Russia** and **Israel-Hamas Wars**: Ongoing coverage and updates on the conflicts.\n",
       "\n",
       "## Recent Developments\n",
       "- **Entertainment**: Hoda Kotb announces departure from the 'Today' show.\n",
       "- **Politics**: Ongoing discussions and events related to the upcoming 2024 elections, including implications for Democratic candidates.\n",
       "\n",
       "CNN also engages users through a feedback mechanism for ads and technical issues. The site is designed to keep readers informed and engaged with the latest developments in various domains."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://cnn.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "95eb84ed-c92d-4574-8c06-c32b51af8247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "# Yahoo Finance - Stock Market Live\n",
       "\n",
       "Yahoo Finance provides comprehensive coverage of the stock market, finance, and business news. The homepage features an array of topics including live stock quotes, market data, and news highlights. Key areas include:\n",
       "\n",
       "## News Updates\n",
       "- **Economy**: The U.S. appears to be emerging from an economic slowdown with positive changes on the horizon. Recent reports indicate a 3% annualized growth rate and decreasing jobless claims.\n",
       "- **Corporate Highlights**:\n",
       "  - **Costco** reported Q4 earnings that beat expectations, however, revenue fell short.\n",
       "  - **BlackBerry** announced a loss in its quarterly earnings report.\n",
       "  - **Trump** has launched a new venture focused on luxury watches.\n",
       "- **Market Performance**: Asian stocks show gains, influenced by optimistic trends in the China and U.S. markets.\n",
       "\n",
       "## Market Data\n",
       "- The site features **real-time stock data**, with highlights such as:\n",
       "  - **Futures and Commodities**: S&P 500 futures down slightly, along with Dow and Nasdaq futures.\n",
       "  - Notable movements include major stocks such as **NVIDIA**, **Micron**, and **Alibaba** showing positive trends.\n",
       "\n",
       "## Sector Insights\n",
       "- Investments are notably strong in technology and consumer sectors, bolstered by recent earnings reports and market forecasts.\n",
       "\n",
       "## Personal Finance\n",
       "- The site includes resources for personal finance management, such as mortgage rates, credit cards, and investment advice.\n",
       "\n",
       "## Investment Ideas\n",
       "- A collection of **stocks** and **ETFs** currently attracting attention, including growth stocks and top daily gainers.\n",
       "\n",
       "Overall, Yahoo Finance serves as a robust platform for investors and financial enthusiasts, offering timely news, dynamic market insights, and a wide array of financial tools."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display_summary(\"https://finance.yahoo.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ebbb48-ec41-4865-bcab-4c00ae88eec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

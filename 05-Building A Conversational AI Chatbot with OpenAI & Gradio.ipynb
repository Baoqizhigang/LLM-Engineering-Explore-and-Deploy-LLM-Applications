{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f80e5dbc-5715-4a04-bfed-3bddb5626f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f251103-c166-4125-9227-0280602ff55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables in a file called .env\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['ANTHROPIC_API_KEY'] = os.getenv('ANTHROPIC_API_KEY', 'your-key-if-not-using-env')\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY', 'your-key-if-not-using-env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b91627-dfdb-4101-9d37-aefc9a555633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize\n",
    "\n",
    "openai = OpenAI()\n",
    "MODEL = \"gpt-4o-mini\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5512561a-c543-4754-bc99-290f460c9d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2c4def-6f30-498a-90c3-acbd1723e42f",
   "metadata": {},
   "source": [
    "## Reminder of the structure of prompt messages to OpenAI:\n",
    "\n",
    "```\n",
    "[\n",
    "    {\"role\": \"system\", \"content\": \"system message here\"},\n",
    "    {\"role\": \"user\", \"content\": \"first user prompt here\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"the assistant's response\"},\n",
    "    {\"role\": \"user\", \"content\": \"the new user prompt\"},\n",
    "]\n",
    "```\n",
    "\n",
    "We will write a function `chat(message, history)` where:\n",
    "**message** is the prompt to use\n",
    "**history** is a list of pairs of user message with assistant's reply\n",
    "\n",
    "```\n",
    "[\n",
    "    [\"user said this\", \"assistant replied\"],\n",
    "    [\"then user said this\", \"and assistant replied again],\n",
    "    ...\n",
    "]\n",
    "```\n",
    "We will convert this history into the prompt style for OpenAI, then call OpenAI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe2353a0-df57-4ab1-9410-45689ea646b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    # message: The latest message input from the user.\n",
    "    # history: A list of tuples containing previous user and assistant messages.\n",
    "\n",
    "    # Initialize the conversation with a system message that sets the assistant's behavior.\n",
    "    # The OpenAI API expects messages as a list of dictionaries with \"role\" and \"content\" keys.\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "\n",
    "    # The conversation history is stored as a list of tuples, where each tuple contains a user message and the corresponding assistant reply.\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assitant_message})\n",
    "    # Add the latest user message to the conversation.\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    print(\"History is: \")\n",
    "    print(history)\n",
    "    print(\"And messages is: \")\n",
    "    print(messages)\n",
    "\n",
    "    stream = openai.chat.completions.create(model = MODEL, messages = messages, stream = True)\n",
    "\n",
    "    response = \"\"\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f827ee75-c622-4a99-85ad-fe535fd07b3e",
   "metadata": {},
   "source": [
    "### **Function Callback:**\n",
    "* Gradio uses the **fn** parameter to know which function to invoke for processing inputs.\n",
    "### **User Interaction Flow:**\n",
    "* User types a message in the chat interface.\n",
    "* Gradio passes this message to the **chat** function.\n",
    "* The **chat** function processes the message and returns a response.\n",
    "* Gradio displays the assistant's response in the chat interface.\n",
    "### **.launch()** : What It Does \n",
    "* **Launches the Interface:** Starts a local web server and opens the chat interface in a new browser tab or inline (if in a Jupyter environment).\n",
    "* **Makes the App Accessible:** Allows users to interact with your chatbot via a web interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e941651-2ba4-49ce-bd9a-e6c50edf98f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is: \n",
      "[]\n",
      "And messages is: \n",
      "[{'role': 'system', 'content': 'You are a helpful assistant'}, {'role': 'user', 'content': 'What kind of nice features dose 2025 Kia Sportage EX have?'}]\n"
     ]
    }
   ],
   "source": [
    "# gr.ChatInterface: A class provided by the Gradio library specifically designed for creating chat-based interfaces.\n",
    "# gr.ChatInterface(fn=chat): Creates a chat interface bound to your chat function, which processes messages.\n",
    "# .launch(): Starts the Gradio app, making the chat interface accessible to users.\n",
    "gr.ChatInterface(fn = chat, type = \"tuples\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf93909b-fe8b-4a17-913a-ed4c0f31202a",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message += \"\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, \\\n",
    "but remind the customer to look at hats!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5950a0e-6b15-4657-af8a-c0ff7c1184e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7864/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "History is: \n",
      "[]\n",
      "And messages is: \n",
      "[{'role': 'system', 'content': 'You are a helpful assistant\\nIf the customer asks for shoes, you should respond that shoes are not on sale today, but remind the customer to look at hats!'}, {'role': 'user', 'content': 'I want to buy a pair of shoes, some books, but definitely not hats.'}]\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn = chat, type = \"tuples\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88e638ce-b28b-4cbb-a27e-0c7cd044ae38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\": \"system\", \"content\": system_message}]\n",
    "    for user_message, assistant_message in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user_message})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_message})\n",
    "\n",
    "    if 'belt' in message:\n",
    "        messages.append({\"role\": \"system\", \"content\": \"For added context, the store does not sell belts, \\\n",
    "but be sure to point out other items on sale\"})\n",
    "\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "\n",
    "    stream = openai.chat.completions.create(model = MODEL, messages = messages, stream = True)\n",
    "\n",
    "    response = \"\"\n",
    "\n",
    "    for chunk in stream:\n",
    "        response += chunk.choices[0].delta.content or \"\"\n",
    "        yield response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0998f675-0301-47bc-bac4-7558e1bef3cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Programms\\Lib\\site-packages\\gradio\\components\\chatbot.py:228: UserWarning: The 'tuples' format for chatbot messages is deprecated and will be removed in a future version of Gradio. Please set type='messages' instead, which uses openai-style 'role' and 'content' keys.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.ChatInterface(fn = chat, type = \"tuples\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cfff922-706c-4daf-947f-aacb166e6ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

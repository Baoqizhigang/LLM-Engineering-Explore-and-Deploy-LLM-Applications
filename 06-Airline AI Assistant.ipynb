{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1d16971-b3ab-41af-8956-246c6801b904",
   "metadata": {},
   "source": [
    "### **Key Libraries:**\n",
    "* **os and json:** Standard Python libraries for managing environment variables and handling JSON data.\n",
    "* **dotenv:** Loads environment variables from a .env file, allowing secure API key handling.\n",
    "* **OpenAI:** Provides the OpenAI API’s client for interacting with language models.\n",
    "* **Gradio:** A framework for creating web interfaces for ML models, useful for quick and user-friendly AI demos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f6187b01-ae85-4660-8610-80d0f57277bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e9813b5a-c894-4a36-998b-01cc659f5136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "\n",
    "load_dotenv()\n",
    "os.environ['OPENAI_API_KEY'] = os.getenv('OPENAI_API_KEY', 'your-key-if-not-using-env')\n",
    "MODEL = \"gpt-4o-mini\"\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "559c0f57-be43-4d18-a633-0f4df25a79ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a helpful assistant for an Airline called FlightAI. \"\n",
    "system_message += \"Give short, courteous answers, no more than 1 sentence. \"\n",
    "system_message += \"Always be accurate. If you don't know the answer, say so.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "640049c1-19f0-4d6e-bc80-10991b0e22fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7881\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7881/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\" : \"system\", \"content\" : system_message}]\n",
    "    for human, assistant in history:\n",
    "        messages.append({\"role\" : \"user\", \"content\" : human})\n",
    "        messages.append({\"role\" : \"assistant\", \"content\" : assistant})\n",
    "    messages.append({\"role\" : \"user\", \"content\" : message})\n",
    "    response = openai.chat.completions.create(model=MODEL, messages=messages)\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "gr.ChatInterface(fn=chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3355c1b8-e285-4eff-9812-7c8a2935e533",
   "metadata": {},
   "source": [
    "## Tools\n",
    "\n",
    "Tools are an incredibly powerful feature provided by the frontier LLMs.\n",
    "\n",
    "With tools, you can write a function, and have the LLM call that function as part of its response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5b242fcc-9191-4c53-862e-6b0a22cd775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's start by making a useful function\n",
    "\n",
    "ticket_prices = {\"london\": \"$799\", \"paris\": \"$899\", \"tokyo\": \"$1400\", \"berlin\": \"$499\"}\n",
    "\n",
    "def get_ticket_price(destination_city):\n",
    "    print(f\"Tool get_ticket_price called for {destination_city}\")\n",
    "    city = destination_city.lower()\n",
    "    return ticket_prices.get(city, \"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ab2db564-d562-4501-a504-ffa1fc51fda8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for London\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'$799'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"London\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "36cfbe3f-8226-47ea-987b-85fd3ab729dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tool get_ticket_price called for China\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Unknown'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ticket_price(\"China\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2768465c-5dd6-412d-812e-534936d5887b",
   "metadata": {},
   "source": [
    "## Getting OpenAI to use our Tool\n",
    "There's some fiddly stuff to allow OpenAI \"to call our tool\"\n",
    "\n",
    "This **price_function** dictionary specifies the function’s details, including its name, description, and parameters. This setup is crucial for an AI model to understand when and how to use the **get_ticket_price** function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e3551dc5-2e20-43c7-bba6-f808537e0981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's a particular dictionary structure that's required to describe our function:\n",
    "\n",
    "price_function = {\n",
    "    # Identify the function by name, allowing the AI model to recognize and invoke it directly.\n",
    "    \"name\" : \"get_ticket_price \",\n",
    "    # \"description\": Provides an explanation of when and why the function should be used, guiding the model to call it specifically when ticket price information is requested.\n",
    "    \"description\" : \"Get the price of a return ticket to the destination city. Call this whenever you need to know the ticket price, for example when a customer asks 'How much is a ticket to this city'\",\n",
    "    # \"parameters\": Defines the structure of inputs required by the function\n",
    "    \"parameters\" : {\n",
    "        \"type\" : \"object\", # Specify that the parameters will be in object form\n",
    "        #\"properties\":  Lists required fields within the function’s parameters.\n",
    "        \"properties\" : {\n",
    "            # A required field describing the destination for which the user seeks a ticket price.\n",
    "            \"destination_city\" : {\n",
    "            \"type\" : \"string\",\n",
    "            \"description\" : \"The city that the customer wants to travel to\",\n",
    "        },\n",
    "    },\n",
    "    # Ensure that destination_city is provided whenever this function is called, as it’s essential for retrieving the price.\n",
    "    \"required\" : [\"destination_city\"],\n",
    "    # Restrict inputs to just the specified parameters, improving reliability.\n",
    "    \"additionalProperties\" : False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "888faca5-e5af-4fea-925e-330fb2dc5e16",
   "metadata": {},
   "source": [
    "###  **Significance of this Structure in AI Systems**\n",
    "* **Tool Functionality:** The AI assistant can reference the **tools** list to check available functions and their usage context. It allows the assistant to dynamically choose and call **get_ticket_price** whenever the user asks a price-related question.\n",
    "* **Parameter Validation:** By defining required parameters, the assistant ensures each call is complete and accurate, minimizing user misunderstandings.\n",
    "* **Enhanced User Experience:** Structured descriptions help the model know when each tool is appropriate, improving response accuracy and making interactions smoother for the end user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e1fea742-b02a-4c8d-80da-14d07745f092",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This list of tools provides a standardized way for an AI model to access various functions it might use during interactions.\n",
    "# \"type\": \"function\": Specifies that each item in the list is a function type, indicating the role of the item.\n",
    "# \"function\": price_function: Associates the actual function dictionary (price_function) with the tool.\n",
    "tools = [{\"type\" : \"function\", \"function\" : price_function}]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59f8552a-c797-4126-ad1d-13831e473fd0",
   "metadata": {},
   "source": [
    "## Getting OpenAI to use our Tool\n",
    "\n",
    "What we actually do is give the LLM the opportunity to inform us that it wants us to run the tool."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8966608a-9f3b-4222-b194-4701dff4a22e",
   "metadata": {},
   "source": [
    "## **Technical and AI Concepts**\n",
    "\n",
    "This structured approach enables the AI to interactively use tools in response to user requests, adding functionality that goes beyond basic text generation. \n",
    "\n",
    "* **Tool Invocation:** By monitoring **finish_reason** for \"tool_calls,\" the AI can selectively call predefined functions, enabling it to perform dynamic tasks based on context.\n",
    "* **Re-prompting for Contextual Response:** After handling the tool call, the function makes a second OpenAI API call with updated messages. This technique helps ensure the assistant’s response is well-aligned with the context and tool output.\n",
    "* **Error Handling Potential:** This structure provides flexibility in handling various tool outputs, but adding checks (e.g., for invalid city names) to **handle_tool_call** could further refine error handling.\n",
    "  \n",
    "This structured approach enables the AI to interactively use tools in response to user requests, adding functionality that goes beyond basic text generation. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c122d9c7-7094-4500-a4e1-c5f7ce93ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    messages = [{\"role\" : \"system\", \"content\" : system_message}]\n",
    "    for human, assistant in history:\n",
    "        messages.append({\"role\" : \"user\", \"content\" : human})\n",
    "        messages.append({\"role\" : \"assistant\", \"content\" : assistant})\n",
    "    messages.append({\"role\" : \"user\", \"content\" : message})\n",
    "\n",
    "    # Call the OpenAI API with tools as an additional parameter, enabling the assistant to invoke specific functions if needed (like get_ticket_price).\n",
    "    # The tools parameter allows the assistant to check whether a tool (function) should be called based on user input.\n",
    "    response = openai.chat.completions.create(model = MODEL, messages = messages, tools = tools)\n",
    "\n",
    "    # check if the response’s end reason was a tool call, meaning the assistant identified that a function like get_ticket_price could address the user’s query.\n",
    "    if response.choice[0].finish_reason == \"tool_calls\": \n",
    "        # Extract the message that triggered the tool call.\n",
    "        message = response.choices[0].message \n",
    "        # Invoke handle_tool_call, which processes the tool call by:\n",
    "            # ---- Extracting parameters (like the destination city).\n",
    "            # ----- Calling the relevant function (get_ticket_price).\n",
    "            # ----- Formatting a response based on the function output.\n",
    "        response, city = handle_tool_call(message)\n",
    "        # Append the tool call message and the tool’s response to maintain conversation continuity.\n",
    "        messages.append(message)\n",
    "        messages.append(response)\n",
    "        # Call OpenAI again, providing updated messages (with tool output) to complete the user interaction.\n",
    "        response = openai.chat.completions.create(model = MODEL, messages = messages)\n",
    "\n",
    "    # Deliver the final response to the user, incorporating any tool output as needed.\n",
    "    return response.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af336c6-58c7-4ab5-b7be-a780bdd6ac61",
   "metadata": {},
   "source": [
    "## **How This Fits into the AI Workflow**\n",
    "\n",
    "This function integrates seamlessly into the **chat** flow, enabling the AI assistant to handle tool-based requests dynamically and return accurate, contextually relevant information to the user.\n",
    "\n",
    "* **Dynamic Tool Execution:** This function dynamically extracts the required information (destination city), calls the relevant tool (**get_ticket_price**), and prepares the data for the AI model.\n",
    "* **Clear JSON Structure:** By packaging the response in JSON, it ensures consistent formatting, which aids the AI in understanding and incorporating the tool’s output into its responses.\n",
    "* **Tool Call Management:** Using the **tool_call_id** ensures that each response is linked back to the specific tool invocation, enhancing traceability and reliability.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cd7be151-145f-40a6-af21-042708f605c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to write that function handle_tool_call:\n",
    "\n",
    "def handle_tool_call(message):\n",
    "    # Purpose: Selects the first tool call from the AI’s response (in case of multiple tools, which here we assume to be one).\n",
    "    # Mechanism: Accesses message.tool_calls[0] to retrieve the necessary tool call information, including arguments and tool call ID.\n",
    "    tool_call = message.tool_calls[0]\n",
    "    # Purpose: Extracts the city for which the user wants to know the ticket price.\n",
    "    # json.loads(tool_call.function.arguments): Parses the tool call arguments (which are in JSON format) to access specific input values.\n",
    "    arguments = json.loads(tool_call.function.arguments)\n",
    "    # Retrieve the destination_city value, expected to match a city in the ticket_prices dictionary from earlier.\n",
    "    city = arguments.get(\"destination_city\")\n",
    "    # Passes city to get_ticket_price, which returns the ticket price if available, or “Unknown” if the city is not found.\n",
    "    price = get_ticket_price(city)\n",
    "    # Construct a structured response that can be incorporated into the AI’s conversational flow.\n",
    "    response = {\n",
    "        # Indicate this response comes from a tool, helping the AI to process it correctly in context.\n",
    "        \"role\" : \"tool\", \n",
    "        #  Convert the destination city and ticket price data into JSON format for clarity and consistency in the response.\n",
    "        \"content\" : json.dumps({\"destination_city\": city, \"price\": price}),\n",
    "        # Associate the response with the specific tool call ID, ensuring accurate linkage between request and response.\n",
    "        \"tool_call_id\" : message.tool_calls[0].id\n",
    "    }\n",
    "    # Return the constructed response and the city name for potential further use in the chat function.\n",
    "    # The response dictionary is intended for use in the conversation, while city might be used for logging or additional processing.\n",
    "    return response, city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4451dd9b-836b-4348-834d-997b5c10b7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7886\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7886/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\gradio\\queueing.py\", line 622, in process_events\n",
      "    response = await route_utils.call_process_api(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\gradio\\route_utils.py\", line 323, in call_process_api\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\gradio\\blocks.py\", line 2014, in process_api\n",
      "    result = await self.call_function(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\gradio\\blocks.py\", line 1565, in call_function\n",
      "    prediction = await fn(*processed_input)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\gradio\\utils.py\", line 813, in async_wrapper\n",
      "    response = await f(*args, **kwargs)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\gradio\\chat_interface.py\", line 638, in _submit_fn\n",
      "    response = await anyio.to_thread.run_sync(\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\anyio\\to_thread.py\", line 56, in run_sync\n",
      "    return await get_async_backend().run_sync_in_worker_thread(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 2134, in run_sync_in_worker_thread\n",
      "    return await future\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 851, in run\n",
      "    result = context.run(func, *args)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Administrator\\AppData\\Local\\Temp\\ipykernel_32000\\4147629023.py\", line 10, in chat\n",
      "    response = openai.chat.completions.create(model = MODEL, messages = messages, tools = tools)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\openai\\_utils\\_utils.py\", line 274, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\openai\\resources\\chat\\completions.py\", line 704, in create\n",
      "    return self._post(\n",
      "           ^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\openai\\_base_client.py\", line 1270, in post\n",
      "    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\openai\\_base_client.py\", line 947, in request\n",
      "    return self._request(\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"D:\\Programms\\Lib\\site-packages\\openai\\_base_client.py\", line 1051, in _request\n",
      "    raise self._make_status_error_from_response(err.response) from None\n",
      "openai.BadRequestError: Error code: 400 - {'error': {'message': \"Invalid 'tools[0].function.name': string does not match pattern. Expected a string that matches the pattern '^[a-zA-Z0-9_-]+$'.\", 'type': 'invalid_request_error', 'param': 'tools[0].function.name', 'code': 'invalid_value'}}\n"
     ]
    }
   ],
   "source": [
    "gr.ChatInterface(fn = chat, type = \"messages\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459aac8d-ddb9-4349-88e9-a70084a27009",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
